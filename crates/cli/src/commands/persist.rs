//! Persist command implementation for session state management.

use chrono::{DateTime, Utc};
use domain::entities::{Session, Spec};
use domain::repositories::{SessionRepository, SpecRepository};
use infrastructure::persistence::{
    BackupAdapter, SessionJsonRepo, SpecJsonRepo, TaskJsonRepo,
};
use std::io::{self, Write};
use std::path::Path;

/// Saves all session state to persistent storage.
pub async fn save() -> anyhow::Result<()> {
    let data_dir = Path::new(".aad/data");
    let backup_dir = Path::new(".aad/backups");

    // Initialize repositories
    let spec_repo = SpecJsonRepo::new(data_dir.join("specs"));
    let task_repo = TaskJsonRepo::new(data_dir.join("tasks"));
    let session_repo = SessionJsonRepo::new(data_dir.join("sessions"));
    let backup_adapter = BackupAdapter::new(backup_dir);

    // Create backup of existing data if it exists
    if data_dir.exists() {
        println!("ğŸ“¦ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆä¸­...");

        // Backup specs directory
        for entry in std::fs::read_dir(data_dir.join("specs"))
            .unwrap_or_else(|_| std::fs::read_dir(".").unwrap())
        {
            if let Ok(entry) = entry {
                let path = entry.path();
                if path.extension().and_then(|s| s.to_str()) == Some("json") {
                    backup_adapter.backup(&path).await?;
                }
            }
        }

        // Cleanup old backups (keep last 10)
        backup_adapter
            .cleanup_old_backups(BackupAdapter::DEFAULT_KEEP_COUNT)
            .await?;
    }

    println!("ğŸ’¾ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¿å­˜ä¸­...");

    // Load existing data
    let specs: Vec<Spec> = spec_repo.find_all().await?;
    let active_sessions: Vec<Session> = session_repo.find_active().await?;

    // Save all specs to ensure persistence
    for spec in &specs {
        spec_repo.save(spec).await?;
    }

    // Save all active sessions
    for session in &active_sessions {
        session_repo.save(session).await?;
    }

    // TODO: Load and save tasks from .aad/tasks/ directory
    // Currently, tasks are not being persisted as there's no source to load from

    println!("âœ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ (.aad/data/)");
    println!("  â€¢ ä»•æ§˜: {} ä»¶", specs.len());
    println!("  â€¢ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³: {} ä»¶", active_sessions.len());

    Ok(())
}

/// Restores session state from a backup timestamp.
pub async fn restore(timestamp: &str) -> anyhow::Result<()> {
    let backup_dir = Path::new(".aad/backups");
    let data_dir = Path::new(".aad/data");

    if !backup_dir.exists() {
        anyhow::bail!("ã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
    }

    // Parse timestamp
    let _parsed_timestamp: DateTime<Utc> = timestamp.parse().map_err(|_| {
        anyhow::anyhow!("ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å½¢å¼ã§ã™ã€‚ISO 8601å½¢å¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 2026-01-18T10:30:00Zï¼‰")
    })?;

    // Find backup files matching the timestamp
    let backup_adapter = BackupAdapter::new(backup_dir);
    let mut backup_files = Vec::new();

    let mut entries = tokio::fs::read_dir(backup_dir).await?;
    while let Some(entry) = entries.next_entry().await? {
        let path = entry.path();
        if let Some(file_name) = path.file_name().and_then(|n| n.to_str()) {
            if file_name.contains(timestamp) && file_name.ends_with(".bak") {
                backup_files.push(path);
            }
        }
    }

    if backup_files.is_empty() {
        anyhow::bail!(
            "ã‚¨ãƒ©ãƒ¼: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— '{}' ã«å¯¾å¿œã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
            timestamp
        );
    }

    // Confirm with user
    print!(
        "âš   ç¾åœ¨ã®çŠ¶æ…‹ã¯ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚ç¶šè¡Œã—ã¾ã™ã‹? (y/N): "
    );
    io::stdout().flush()?;

    let mut input = String::new();
    io::stdin().read_line(&mut input)?;

    if !input.trim().eq_ignore_ascii_case("y") {
        println!("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ");
        return Ok(());
    }

    // Restore backups
    println!("ğŸ“‚ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒä¸­...");

    for backup_path in &backup_files {
        let file_name = backup_path
            .file_name()
            .and_then(|n| n.to_str())
            .ok_or_else(|| anyhow::anyhow!("ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å"))?;

        // Extract original file path from backup name
        // Format: <original-name>.<timestamp>.bak
        let parts: Vec<&str> = file_name.rsplitn(3, '.').collect();
        if parts.len() >= 3 {
            let original_name = parts[2];

            // Determine target path based on file name
            let target_path = if original_name.starts_with("SPEC-") {
                data_dir.join("specs").join(format!("{}.json", original_name))
            } else if original_name.starts_with("TASK-") {
                data_dir.join("tasks").join(format!("{}.json", original_name))
            } else {
                data_dir.join("sessions").join(format!("{}.json", original_name))
            };

            backup_adapter.restore(backup_path, &target_path).await?;
        }
    }

    println!("âœ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒã—ã¾ã—ãŸ");
    println!("  â€¢ å¾©å…ƒã—ãŸãƒ•ã‚¡ã‚¤ãƒ«: {} ä»¶", backup_files.len());

    Ok(())
}

/// Lists all available backups.
pub async fn list() -> anyhow::Result<()> {
    let backup_dir = Path::new(".aad/backups");

    if !backup_dir.exists() {
        println!("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
        return Ok(());
    }

    // Collect all backup files with their timestamps
    let mut backups: Vec<(String, std::time::SystemTime)> = Vec::new();
    let mut entries = tokio::fs::read_dir(backup_dir).await?;

    while let Some(entry) = entries.next_entry().await? {
        let path = entry.path();
        if path.extension().and_then(|s| s.to_str()) == Some("bak") {
            let metadata = tokio::fs::metadata(&path).await?;
            if let Ok(modified) = metadata.modified() {
                if let Some(file_name) = path.file_name().and_then(|n| n.to_str()) {
                    backups.push((file_name.to_string(), modified));
                }
            }
        }
    }

    if backups.is_empty() {
        println!("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
        return Ok(());
    }

    // Group backups by timestamp
    use std::collections::HashMap;
    let mut grouped: HashMap<String, Vec<String>> = HashMap::new();

    for (file_name, _) in &backups {
        // Extract timestamp from filename
        // Format: <original-name>.<timestamp>.bak
        let parts: Vec<&str> = file_name.rsplitn(3, '.').collect();
        if parts.len() >= 2 {
            let timestamp = parts[1];
            grouped
                .entry(timestamp.to_string())
                .or_insert_with(Vec::new)
                .push(file_name.clone());
        }
    }

    // Sort timestamps
    let mut timestamps: Vec<_> = grouped.keys().collect();
    timestamps.sort_by(|a, b| b.cmp(a)); // Newest first

    println!("ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§:\n");

    for (idx, timestamp) in timestamps.iter().enumerate() {
        let files = &grouped[*timestamp];
        println!(
            "  {}. {} ({} ãƒ•ã‚¡ã‚¤ãƒ«)",
            idx + 1,
            timestamp,
            files.len()
        );

        // Extract spec IDs if available
        let mut spec_ids = Vec::new();
        for file in files {
            if file.starts_with("SPEC-") {
                let parts: Vec<&str> = file.split('.').collect();
                if !parts.is_empty() {
                    spec_ids.push(parts[0]);
                }
            }
        }

        if !spec_ids.is_empty() {
            println!("     ä»•æ§˜: {}", spec_ids.join(", "));
        }
    }

    println!();
    Ok(())
}
